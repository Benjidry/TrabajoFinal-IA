{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-11 05:56:04.212199: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-11 05:56:04.214250: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-05-11 05:56:04.240800: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-05-11 05:56:04.240833: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-05-11 05:56:04.241515: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-05-11 05:56:04.245680: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-05-11 05:56:04.246404: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-11 05:56:05.178491: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# LabelMaps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Creacion de Labelmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python ./csv_to_labelmap.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TFRecords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python ./generate_tfRecord.py \"Playing Cards.v4-yolov8n.tensorflow/train/_annotations.csv\" label_map.pbtxt \"Playing Cards.v4-yolov8n.tensorflow/train\" train.record"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python ./generate_tfRecord.py \"Playing Cards.v4-yolov8n.tensorflow/test/_annotations.csv\" label_map.pbtxt \"Playing Cards.v4-yolov8n.tensorflow/test\" test.record"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Valid Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python ./generate_tfRecord.py \"Playing Cards.v4-yolov8n.tensorflow/valid/_annotations.csv\" label_map.pbtxt \"Playing Cards.v4-yolov8n.tensorflow/valid\" valid.record"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wget\n",
    "import tarfile\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enviroment Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Can be configured\n",
    "DATASET_DIRECTORY = \"/tf/dataset/workspaceCards/\"\n",
    "OBJECT_DETECTION_DIRECTORY = \"/tf/tensorflow/models/research/object_detection/\"\n",
    "\n",
    "MODEL_NAME = \"ssd_resnet152_v1_fpn_1024x1024_coco17_tpu-8\"\n",
    "MODEL_LINK = \"http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_resnet152_v1_fpn_1024x1024_coco17_tpu-8.tar.gz\"\n",
    "MODEL_CONFIG = \"ssd_mobilenet_v2_pets_keras.config\"\n",
    "MODELS_FOLDER = OBJECT_DETECTION_DIRECTORY+\"samples/configs/\"\n",
    "MODEL_FILEPATH = os.path.join(MODELS_FOLDER, MODEL_CONFIG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "FINE_CHECKPOINT = DATASET_DIRECTORY + \"models/\" + MODEL_NAME + \"/checkpoint/cpkt-0\"\n",
    "TRAIN_TFRECORD = DATASET_DIRECTORY + \"train.record\"\n",
    "TEST_TFRECORD = DATASET_DIRECTORY + \"test.record\"\n",
    "LABEL_MAP = DATASET_DIRECTORY + \"label_map.pbtxt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 12\n",
    "NUM_STEPS = 10000\n",
    "NUM_CLASSES = 52\n",
    "NUM_EVAL_STEPS = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Downloading ML Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wget.download(MODEL_LINK, out='./models')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Unzip MLModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tar = tarfile.open('./models/' + MODEL_NAME + \".tar.gz\")\n",
    "tar.extractall('./models/')\n",
    "tar.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modify config file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(MODEL_FILEPATH) as f:\n",
    "    s = f.read()\n",
    "\n",
    "with open(MODEL_FILEPATH, 'w') as f:\n",
    "        # fine_tune_checkpoint\n",
    "    s = re.sub('fine_tune_checkpoint: \".*?\"',\n",
    "               'fine_tune_checkpoint: \"{}\"'.format(FINE_CHECKPOINT), s)\n",
    "    \n",
    "    # tfrecord files train and test.\n",
    "    s = re.sub(\n",
    "        '(input_path: \".*?)(train.record)(.*?\")', 'input_path: \"{}\"'.format(TRAIN_TFRECORD), s)\n",
    "    s = re.sub(\n",
    "        '(input_path: \".*?)(val.record)(.*?\")', 'input_path: \"{}\"'.format(TEST_TFRECORD), s)\n",
    "\n",
    "    # label_map_path\n",
    "    s = re.sub(\n",
    "        'label_map_path: \".*?\"', 'label_map_path: \"{}\"'.format(LABEL_MAP), s)\n",
    "\n",
    "    # Set training batch_size.\n",
    "    s = re.sub('batch_size: [0-9]+',\n",
    "               'batch_size: {}'.format(BATCH_SIZE), s)\n",
    "\n",
    "    # Set training steps, num_steps\n",
    "    s = re.sub('num_steps: [0-9]+',\n",
    "               'num_steps: {}'.format(NUM_STEPS), s)\n",
    "    \n",
    "    # Set number of classes num_classes.\n",
    "    s = re.sub('num_classes: [0-9]+',\n",
    "               'num_classes: {}'.format(NUM_CLASSES), s)\n",
    "    f.write(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# An untested config for Keras SSD with MobileNetV2 configured for Oxford-IIIT Pets Dataset.\n",
      "# Users should configure the fine_tune_checkpoint field in the train config as\n",
      "# well as the label_map_path and input_path fields in the train_input_reader and\n",
      "# eval_input_reader. Search for \"PATH_TO_BE_CONFIGURED\" to find the fields that\n",
      "# should be configured.\n",
      "\n",
      "model {\n",
      "  ssd {\n",
      "    num_classes: 52\n",
      "    box_coder {\n",
      "      faster_rcnn_box_coder {\n",
      "        y_scale: 10.0\n",
      "        x_scale: 10.0\n",
      "        height_scale: 5.0\n",
      "        width_scale: 5.0\n",
      "      }\n",
      "    }\n",
      "    matcher {\n",
      "      argmax_matcher {\n",
      "        matched_threshold: 0.5\n",
      "        unmatched_threshold: 0.5\n",
      "        ignore_thresholds: false\n",
      "        negatives_lower_than_unmatched: true\n",
      "        force_match_for_each_row: true\n",
      "      }\n",
      "    }\n",
      "    similarity_calculator {\n",
      "      iou_similarity {\n",
      "      }\n",
      "    }\n",
      "    anchor_generator {\n",
      "      ssd_anchor_generator {\n",
      "        num_layers: 6\n",
      "        min_scale: 0.2\n",
      "        max_scale: 0.95\n",
      "        aspect_ratios: 1.0\n",
      "        aspect_ratios: 2.0\n",
      "        aspect_ratios: 0.5\n",
      "        aspect_ratios: 3.0\n",
      "        aspect_ratios: 0.3333\n",
      "        reduce_boxes_in_lowest_layer: true\n",
      "      }\n",
      "    }\n",
      "    image_resizer {\n",
      "      fixed_shape_resizer {\n",
      "        height: 300\n",
      "        width: 300\n",
      "      }\n",
      "    }\n",
      "    box_predictor {\n",
      "      convolutional_box_predictor {\n",
      "        min_depth: 0\n",
      "        max_depth: 0\n",
      "        num_layers_before_predictor: 0\n",
      "        use_dropout: false\n",
      "        dropout_keep_probability: 0.8\n",
      "        kernel_size: 3\n",
      "        box_code_size: 4\n",
      "        apply_sigmoid_to_scores: false\n",
      "        conv_hyperparams {\n",
      "          activation: RELU_6,\n",
      "          regularizer {\n",
      "            l2_regularizer {\n",
      "              weight: 0.00004\n",
      "            }\n",
      "          }\n",
      "          initializer {\n",
      "            truncated_normal_initializer {\n",
      "              stddev: 0.03\n",
      "              mean: 0.0\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    feature_extractor {\n",
      "      type: 'ssd_mobilenet_v2_keras'\n",
      "      min_depth: 16\n",
      "      depth_multiplier: 1.0\n",
      "      conv_hyperparams {\n",
      "        activation: RELU_6,\n",
      "        regularizer {\n",
      "          l2_regularizer {\n",
      "            weight: 0.00004\n",
      "          }\n",
      "        }\n",
      "        initializer {\n",
      "          truncated_normal_initializer {\n",
      "            stddev: 0.03\n",
      "            mean: 0.0\n",
      "          }\n",
      "        }\n",
      "        batch_norm {\n",
      "          train: true,\n",
      "          scale: true,\n",
      "          center: true,\n",
      "          decay: 0.9997,\n",
      "          epsilon: 0.001,\n",
      "        }\n",
      "      }\n",
      "      override_base_feature_extractor_hyperparams: true\n",
      "    }\n",
      "    loss {\n",
      "      classification_loss {\n",
      "        weighted_sigmoid {\n",
      "        }\n",
      "      }\n",
      "      localization_loss {\n",
      "        weighted_smooth_l1 {\n",
      "        }\n",
      "      }\n",
      "      hard_example_miner {\n",
      "        num_hard_examples: 3000\n",
      "        iou_threshold: 0.99\n",
      "        loss_type: CLASSIFICATION\n",
      "        max_negatives_per_positive: 3\n",
      "        min_negatives_per_image: 0\n",
      "      }\n",
      "      classification_weight: 1.0\n",
      "      localization_weight: 1.0\n",
      "    }\n",
      "    normalize_loss_by_num_matches: true\n",
      "    post_processing {\n",
      "      batch_non_max_suppression {\n",
      "        score_threshold: 1e-8\n",
      "        iou_threshold: 0.6\n",
      "        max_detections_per_class: 100\n",
      "        max_total_detections: 100\n",
      "      }\n",
      "      score_converter: SIGMOID\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "train_config: {\n",
      "  batch_size: 12\n",
      "  optimizer {\n",
      "    rms_prop_optimizer: {\n",
      "      learning_rate: {\n",
      "        exponential_decay_learning_rate {\n",
      "          initial_learning_rate: 0.004\n",
      "          decay_steps: 800720\n",
      "          decay_factor: 0.95\n",
      "        }\n",
      "      }\n",
      "      momentum_optimizer_value: 0.9\n",
      "      decay: 0.9\n",
      "      epsilon: 1.0\n",
      "    }\n",
      "    use_moving_average: False\n",
      "  }\n",
      "  fine_tune_checkpoint: \"/tf/dataset/workspaceCards/models/ssd_resnet152_v1_fpn_1024x1024_coco17_tpu-8/checkpoint/cpkt-0\"\n",
      "  from_detection_checkpoint: true\n",
      "  load_all_detection_checkpoint_vars: true\n",
      "  # Note: The below line limits the training process to 200K steps, which we\n",
      "  # empirically found to be sufficient enough to train the pets dataset. This\n",
      "  # effectively bypasses the learning rate schedule (the learning rate will\n",
      "  # never decay). Remove the below line to train indefinitely.\n",
      "  num_steps: 10000\n",
      "  data_augmentation_options {\n",
      "    random_horizontal_flip {\n",
      "    }\n",
      "  }\n",
      "  data_augmentation_options {\n",
      "    ssd_random_crop {\n",
      "    }\n",
      "  }\n",
      "  max_number_of_boxes: 50\n",
      "}\n",
      "\n",
      "train_input_reader: {\n",
      "  tf_record_input_reader {\n",
      "    input_path: \"/tf/dataset/workspaceCards/train.record\"\n",
      "  }\n",
      "  label_map_path: \"/tf/dataset/workspaceCards/label_map.pbtxt\"\n",
      "}\n",
      "\n",
      "eval_config: {\n",
      "  metrics_set: \"coco_detection_metrics\"\n",
      "  num_examples: 1101\n",
      "}\n",
      "\n",
      "eval_input_reader: {\n",
      "  tf_record_input_reader {\n",
      "    input_path: \"/tf/dataset/workspaceCards/test.record\"\n",
      "  }\n",
      "  label_map_path: \"/tf/dataset/workspaceCards/label_map.pbtxt\"\n",
      "  shuffle: false\n",
      "  num_readers: 1\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "!cat {MODEL_FILEPATH}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-11 05:59:04.162441: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-11 05:59:04.163909: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-05-11 05:59:04.189980: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-05-11 05:59:04.190024: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-05-11 05:59:04.190918: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-05-11 05:59:04.195247: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-05-11 05:59:04.195443: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-11 05:59:04.877356: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n",
      "I0511 05:59:06.330771 139763356737536 mirrored_strategy.py:423] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n",
      "INFO:tensorflow:Maybe overwriting train_steps: 10000\n",
      "I0511 05:59:06.345794 139763356737536 config_util.py:552] Maybe overwriting train_steps: 10000\n",
      "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
      "I0511 05:59:06.345932 139763356737536 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
      "Traceback (most recent call last):\n",
      "  File \"/tf/tensorflow/models/research/object_detection/model_main_tf2.py\", line 114, in <module>\n",
      "    tf.compat.v1.app.run()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/app.py\", line 36, in run\n",
      "    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/absl/app.py\", line 308, in run\n",
      "    _run_main(main, args)\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/absl/app.py\", line 254, in _run_main\n",
      "    sys.exit(main(argv))\n",
      "             ^^^^^^^^^^\n",
      "  File \"/tf/tensorflow/models/research/object_detection/model_main_tf2.py\", line 105, in main\n",
      "    model_lib_v2.train_loop(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/object_detection/model_lib_v2.py\", line 531, in train_loop\n",
      "    raise ValueError('train_pb2.load_all_detection_checkpoint_vars '\n",
      "ValueError: train_pb2.load_all_detection_checkpoint_vars unsupported in TF2\n"
     ]
    }
   ],
   "source": [
    "!python /tf/tensorflow/models/research/object_detection/model_main_tf2.py \\\n",
    "    --pipeline_config_path={MODEL_FILEPATH} \\\n",
    "    --model_dir = {} \\\n",
    "    --num_train_steps={NUM_STEPS} \\\n",
    "    --alsologtostderr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
