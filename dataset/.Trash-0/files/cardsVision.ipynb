{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U -q \"tf-models-official\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-11 07:01:38.572011: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-11 07:01:38.573709: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-05-11 07:01:38.596078: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-05-11 07:01:38.596095: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-05-11 07:01:38.596770: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-05-11 07:01:38.600514: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-05-11 07:01:38.601176: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-11 07:01:39.448569: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.python.ops import control_flow_ops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# LabelMaps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Creacion de Labelmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python ./csv_to_labelmap.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# TFRecords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python ./generate_tfRecord.py \"Playing Cards.v4-yolov8n.tensorflow/train/_annotations.csv\" label_map.pbtxt \"Playing Cards.v4-yolov8n.tensorflow/train\" train.record"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python ./generate_tfRecord.py \"Playing Cards.v4-yolov8n.tensorflow/test/_annotations.csv\" label_map.pbtxt \"Playing Cards.v4-yolov8n.tensorflow/test\" test.record"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Valid Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python ./generate_tfRecord.py \"Playing Cards.v4-yolov8n.tensorflow/valid/_annotations.csv\" label_map.pbtxt \"Playing Cards.v4-yolov8n.tensorflow/valid\" valid.record"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wget\n",
    "import tarfile\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enviroment Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Can be configured\n",
    "DATASET_DIRECTORY = \"/tf/dataset/workspaceCards/\"\n",
    "OBJECT_DETECTION_DIRECTORY = \"/tf/tensorflow/models/research/object_detection/\"\n",
    "\n",
    "MODEL_NAME = \"ssd_resnet152_v1_fpn_1024x1024_coco17_tpu-8\"\n",
    "MODEL_LINK = \"http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_resnet152_v1_fpn_1024x1024_coco17_tpu-8.tar.gz\"\n",
    "MODEL_CONFIG = \"ssd_resnet101_v1_fpn_1024x1024_coco17_tpu-8.config\"\n",
    "MODELS_FOLDER = OBJECT_DETECTION_DIRECTORY+\"configs/tf2/\"\n",
    "MODEL_FILEPATH = os.path.join(MODELS_FOLDER, MODEL_CONFIG)\n",
    "MODEL_OUTPUT = DATASET_DIRECTORY + \"modelOutput/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "FINE_CHECKPOINT = DATASET_DIRECTORY + \"models/\" + MODEL_NAME + \"/checkpoint/cpkt-0\"\n",
    "TRAIN_TFRECORD = DATASET_DIRECTORY + \"train.record\"\n",
    "TEST_TFRECORD = DATASET_DIRECTORY + \"test.record\"\n",
    "VALID_TFRECORD = DATASET_DIRECTORY + \"valid.record\"\n",
    "LABEL_MAP = DATASET_DIRECTORY + \"label_map.pbtxt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 12\n",
    "NUM_STEPS = 10000\n",
    "NUM_CLASSES = 52\n",
    "NUM_EVAL_STEPS = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Downloading ML Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wget.download(MODEL_LINK, out='./models')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Unzip MLModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tar = tarfile.open('./models/' + MODEL_NAME + \".tar.gz\")\n",
    "tar.extractall('./models/')\n",
    "tar.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modify config file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(MODEL_FILEPATH) as f:\n",
    "    s = f.read()\n",
    "\n",
    "with open(MODEL_FILEPATH, 'w') as f:\n",
    "\n",
    "    # fine_tune_checkpoint\n",
    "    s = re.sub('fine_tune_checkpoint: \".*?\"',\n",
    "               'fine_tune_checkpoint: \"{}\"'.format(FINE_CHECKPOINT), s)\n",
    "\n",
    "    # tfrecord files train and test.\n",
    "    s = re.sub(\n",
    "        '(input_path: \".*?)(PATH_TO_BE_CONFIGURED/train)(.*?\")', 'input_path: \"{}\"'.format(TRAIN_TFRECORD), s)\n",
    "    s = re.sub(\n",
    "        '(input_path: \".*?)(PATH_TO_BE_CONFIGURED/val)(.*?\")', 'input_path: \"{}\"'.format(TEST_TFRECORD), s)\n",
    "\n",
    "    \n",
    "    # label_map_path\n",
    "    s = re.sub(\n",
    "        'label_map_path: \".*?\"', 'label_map_path: \"{}\"'.format(LABEL_MAP), s)\n",
    "\n",
    "    # Set training batch_size.\n",
    "    s = re.sub('batch_size: [0-9]+',\n",
    "               'batch_size: {}'.format(BATCH_SIZE), s)\n",
    "\n",
    "    # Set training steps, num_steps\n",
    "    s = re.sub('num_steps: [0-9]+',\n",
    "               'num_steps: {}'.format(NUM_STEPS), s)\n",
    "    \n",
    "    # Set number of classes num_classes.\n",
    "    s = re.sub('num_classes: [0-9]+',\n",
    "               'num_classes: {}'.format(NUM_CLASSES), s)\n",
    "\n",
    "    #fine-tune checkpoint type\n",
    "    s = re.sub(\n",
    "        'fine_tune_checkpoint_type: true', 'fine_tune_checkpoint_type: {}'.format('False'), s)\n",
    "        \n",
    "    f.write(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# SSD with Resnet 101 v1 FPN feature extractor, shared box predictor and focal\n",
      "# loss (a.k.a Retinanet).\n",
      "# See Lin et al, https://arxiv.org/abs/1708.02002\n",
      "# Trained on COCO, initialized from Imagenet classification checkpoint\n",
      "# Train on TPU-8\n",
      "#\n",
      "# Achieves 39.5 mAP on COCO17 Val\n",
      "\n",
      "model {\n",
      "  ssd {\n",
      "    inplace_batchnorm_update: true\n",
      "    freeze_batchnorm: false\n",
      "    num_classes: 52\n",
      "    box_coder {\n",
      "      faster_rcnn_box_coder {\n",
      "        y_scale: 10.0\n",
      "        x_scale: 10.0\n",
      "        height_scale: 5.0\n",
      "        width_scale: 5.0\n",
      "      }\n",
      "    }\n",
      "    matcher {\n",
      "      argmax_matcher {\n",
      "        matched_threshold: 0.5\n",
      "        unmatched_threshold: 0.5\n",
      "        ignore_thresholds: false\n",
      "        negatives_lower_than_unmatched: true\n",
      "        force_match_for_each_row: true\n",
      "        use_matmul_gather: true\n",
      "      }\n",
      "    }\n",
      "    similarity_calculator {\n",
      "      iou_similarity {\n",
      "      }\n",
      "    }\n",
      "    encode_background_as_zeros: true\n",
      "    anchor_generator {\n",
      "      multiscale_anchor_generator {\n",
      "        min_level: 3\n",
      "        max_level: 7\n",
      "        anchor_scale: 4.0\n",
      "        aspect_ratios: [1.0, 2.0, 0.5]\n",
      "        scales_per_octave: 2\n",
      "      }\n",
      "    }\n",
      "    image_resizer {\n",
      "      fixed_shape_resizer {\n",
      "        height: 1024\n",
      "        width: 1024\n",
      "      }\n",
      "    }\n",
      "    box_predictor {\n",
      "      weight_shared_convolutional_box_predictor {\n",
      "        depth: 256\n",
      "        class_prediction_bias_init: -4.6\n",
      "        conv_hyperparams {\n",
      "          activation: RELU_6,\n",
      "          regularizer {\n",
      "            l2_regularizer {\n",
      "              weight: 0.0004\n",
      "            }\n",
      "          }\n",
      "          initializer {\n",
      "            random_normal_initializer {\n",
      "              stddev: 0.01\n",
      "              mean: 0.0\n",
      "            }\n",
      "          }\n",
      "          batch_norm {\n",
      "            scale: true,\n",
      "            decay: 0.997,\n",
      "            epsilon: 0.001,\n",
      "          }\n",
      "        }\n",
      "        num_layers_before_predictor: 4\n",
      "        kernel_size: 3\n",
      "      }\n",
      "    }\n",
      "    feature_extractor {\n",
      "      type: 'ssd_resnet101_v1_fpn_keras'\n",
      "      fpn {\n",
      "        min_level: 3\n",
      "        max_level: 7\n",
      "      }\n",
      "      min_depth: 16\n",
      "      depth_multiplier: 1.0\n",
      "      conv_hyperparams {\n",
      "        activation: RELU_6,\n",
      "        regularizer {\n",
      "          l2_regularizer {\n",
      "            weight: 0.0004\n",
      "          }\n",
      "        }\n",
      "        initializer {\n",
      "          truncated_normal_initializer {\n",
      "            stddev: 0.03\n",
      "            mean: 0.0\n",
      "          }\n",
      "        }\n",
      "        batch_norm {\n",
      "          scale: true,\n",
      "          decay: 0.997,\n",
      "          epsilon: 0.001,\n",
      "        }\n",
      "      }\n",
      "      override_base_feature_extractor_hyperparams: true\n",
      "    }\n",
      "    loss {\n",
      "      classification_loss {\n",
      "        weighted_sigmoid_focal {\n",
      "          alpha: 0.25\n",
      "          gamma: 2.0\n",
      "        }\n",
      "      }\n",
      "      localization_loss {\n",
      "        weighted_smooth_l1 {\n",
      "        }\n",
      "      }\n",
      "      classification_weight: 1.0\n",
      "      localization_weight: 1.0\n",
      "    }\n",
      "    normalize_loss_by_num_matches: true\n",
      "    normalize_loc_loss_by_codesize: true\n",
      "    post_processing {\n",
      "      batch_non_max_suppression {\n",
      "        score_threshold: 1e-8\n",
      "        iou_threshold: 0.6\n",
      "        max_detections_per_class: 100\n",
      "        max_total_detections: 100\n",
      "      }\n",
      "      score_converter: SIGMOID\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "train_config: {\n",
      "  fine_tune_checkpoint_version: V2\n",
      "  fine_tune_checkpoint: \"/tf/dataset/workspaceCards/models/ssd_resnet152_v1_fpn_1024x1024_coco17_tpu-8/checkpoint/cpkt-0\"\n",
      "  fine_tune_checkpoint_type: \"classification\"\n",
      "  batch_size: 12\n",
      "  sync_replicas: true\n",
      "  startup_delay_steps: 0\n",
      "  replicas_to_aggregate: 8\n",
      "  use_bfloat16: true\n",
      "  num_steps: 10000\n",
      "  data_augmentation_options {\n",
      "    random_horizontal_flip {\n",
      "    }\n",
      "  }\n",
      "  data_augmentation_options {\n",
      "    random_crop_image {\n",
      "      min_object_covered: 0.0\n",
      "      min_aspect_ratio: 0.75\n",
      "      max_aspect_ratio: 3.0\n",
      "      min_area: 0.75\n",
      "      max_area: 1.0\n",
      "      overlap_thresh: 0.0\n",
      "    }\n",
      "  }\n",
      "  optimizer {\n",
      "    momentum_optimizer: {\n",
      "      learning_rate: {\n",
      "        cosine_decay_learning_rate {\n",
      "          learning_rate_base: .04\n",
      "          total_steps: 100000\n",
      "          warmup_learning_rate: .013333\n",
      "          warmup_steps: 2000\n",
      "        }\n",
      "      }\n",
      "      momentum_optimizer_value: 0.9\n",
      "    }\n",
      "    use_moving_average: false\n",
      "  }\n",
      "  max_number_of_boxes: 100\n",
      "  unpad_groundtruth_tensors: false\n",
      "}\n",
      "\n",
      "train_input_reader: {\n",
      "  label_map_path: \"/tf/dataset/workspaceCards/label_map.pbtxt\"\n",
      "  tf_record_input_reader {\n",
      "    input_path: \"/tf/dataset/workspaceCards/train.record\"\n",
      "  }\n",
      "}\n",
      "\n",
      "eval_config: {\n",
      "  metrics_set: \"coco_detection_metrics\"\n",
      "  use_moving_averages: false\n",
      "}\n",
      "\n",
      "eval_input_reader: {\n",
      "  label_map_path: \"/tf/dataset/workspaceCards/label_map.pbtxt\"\n",
      "  shuffle: false\n",
      "  num_epochs: 1\n",
      "  tf_record_input_reader {\n",
      "    input_path: \"/tf/dataset/workspaceCards/test.record\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "!cat {MODEL_FILEPATH}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-11 07:01:48.005394: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-11 07:01:48.006688: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-05-11 07:01:48.027895: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-05-11 07:01:48.027945: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-05-11 07:01:48.028642: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-05-11 07:01:48.032812: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-05-11 07:01:48.032974: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-11 07:01:48.719545: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n",
      "I0511 07:01:50.373988 139637908746240 mirrored_strategy.py:423] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n",
      "INFO:tensorflow:Maybe overwriting train_steps: 10000\n",
      "I0511 07:01:50.391649 139637908746240 config_util.py:552] Maybe overwriting train_steps: 10000\n",
      "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
      "I0511 07:01:50.391781 139637908746240 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.11/dist-packages/object_detection/model_lib_v2.py:563: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "rename to distribute_datasets_from_function\n",
      "W0511 07:01:50.410000 139637908746240 deprecation.py:50] From /usr/local/lib/python3.11/dist-packages/object_detection/model_lib_v2.py:563: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "rename to distribute_datasets_from_function\n",
      "INFO:tensorflow:Reading unweighted datasets: ['/tf/dataset/workspaceCards/train.record']\n",
      "I0511 07:01:50.425314 139637908746240 dataset_builder.py:162] Reading unweighted datasets: ['/tf/dataset/workspaceCards/train.record']\n",
      "INFO:tensorflow:Reading record datasets for input file: ['/tf/dataset/workspaceCards/train.record']\n",
      "I0511 07:01:50.425786 139637908746240 dataset_builder.py:79] Reading record datasets for input file: ['/tf/dataset/workspaceCards/train.record']\n",
      "INFO:tensorflow:Number of filenames to read: 1\n",
      "I0511 07:01:50.425876 139637908746240 dataset_builder.py:80] Number of filenames to read: 1\n",
      "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
      "W0511 07:01:50.425929 139637908746240 dataset_builder.py:86] num_readers has been reduced to 1 to match input file shards.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.11/dist-packages/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
      "W0511 07:01:50.435084 139637908746240 deprecation.py:50] From /usr/local/lib/python3.11/dist-packages/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.11/dist-packages/object_detection/builders/dataset_builder.py:235: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map()\n",
      "W0511 07:01:50.450981 139637908746240 deprecation.py:50] From /usr/local/lib/python3.11/dist-packages/object_detection/builders/dataset_builder.py:235: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map()\n",
      "Traceback (most recent call last):\n",
      "  File \"/tf/tensorflow/models/research/object_detection/model_main_tf2.py\", line 114, in <module>\n",
      "    tf.compat.v1.app.run()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/platform/app.py\", line 36, in run\n",
      "    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/absl/app.py\", line 308, in run\n",
      "    _run_main(main, args)\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/absl/app.py\", line 254, in _run_main\n",
      "    sys.exit(main(argv))\n",
      "             ^^^^^^^^^^\n",
      "  File \"/tf/tensorflow/models/research/object_detection/model_main_tf2.py\", line 105, in main\n",
      "    model_lib_v2.train_loop(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/object_detection/model_lib_v2.py\", line 563, in train_loop\n",
      "    train_input = strategy.experimental_distribute_datasets_from_function(\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/util/deprecation.py\", line 383, in new_func\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/distribute/distribute_lib.py\", line 1563, in experimental_distribute_datasets_from_function\n",
      "    return self.distribute_datasets_from_function(dataset_fn, options)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/distribute/distribute_lib.py\", line 1554, in distribute_datasets_from_function\n",
      "    return self._extended._distribute_datasets_from_function(  # pylint: disable=protected-access\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/distribute/mirrored_strategy.py\", line 613, in _distribute_datasets_from_function\n",
      "    return input_util.get_distributed_datasets_from_function(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/distribute/input_util.py\", line 144, in get_distributed_datasets_from_function\n",
      "    return input_lib.DistributedDatasetsFromFunction(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/distribute/input_lib.py\", line 1143, in __init__\n",
      "    self.build()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/distribute/input_lib.py\", line 1165, in build\n",
      "    _create_datasets_from_function_with_input_context(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/distribute/input_lib.py\", line 1680, in _create_datasets_from_function_with_input_context\n",
      "    dataset = dataset_fn(ctx)\n",
      "              ^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/object_detection/model_lib_v2.py\", line 554, in train_dataset_fn\n",
      "    train_input = inputs.train_input(\n",
      "                  ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/object_detection/inputs.py\", line 908, in train_input\n",
      "    dataset = INPUT_BUILDER_UTIL_MAP['dataset_build'](\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/object_detection/builders/dataset_builder.py\", line 250, in build\n",
      "    dataset = dataset_map_fn(dataset, decoder.decode, batch_size,\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/object_detection/builders/dataset_builder.py\", line 235, in dataset_map_fn\n",
      "    dataset = dataset.map_with_legacy_function(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/util/deprecation.py\", line 383, in new_func\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/data/ops/dataset_ops.py\", line 4128, in map_with_legacy_function\n",
      "    return map_op._map_v1_with_legacy_function(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/data/ops/map_op.py\", line 85, in _map_v1_with_legacy_function\n",
      "    _ParallelMapDataset(\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/data/ops/map_op.py\", line 148, in __init__\n",
      "    self._map_func = structured_function.StructuredFunctionWrapper(\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/data/ops/structured_function.py\", line 272, in __init__\n",
      "    self._function.add_to_graph(ops.get_default_graph())\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/function.py\", line 579, in add_to_graph\n",
      "    self._create_definition_if_needed()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/function.py\", line 412, in _create_definition_if_needed\n",
      "    self._create_definition_if_needed_impl()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/function.py\", line 430, in _create_definition_if_needed_impl\n",
      "    temp_graph = func_graph_from_py_func(\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/function.py\", line 1007, in func_graph_from_py_func\n",
      "    outputs = func(*func_graph.inputs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/data/ops/structured_function.py\", line 178, in wrapped_fn\n",
      "    ret = wrapper_helper(*args)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/data/ops/structured_function.py\", line 161, in wrapper_helper\n",
      "    ret = autograph.tf_convert(self._func, ag_ctx)(*nested_args)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/autograph/impl/api.py\", line 693, in wrapper\n",
      "    raise e.ag_error_metadata.to_exception(e)\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/autograph/impl/api.py\", line 690, in wrapper\n",
      "    return converted_call(f, args, kwargs, options=options)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/autograph/impl/api.py\", line 439, in converted_call\n",
      "    result = converted_f(*effective_args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/__autograph_generated_fileozf7bza3.py\", line 74, in tf__decode\n",
      "    tensors = ag__.converted_call(ag__.ld(decoder).decode, (ag__.ld(serialized_example),), dict(items=ag__.ld(keys)), fscope)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/autograph/impl/api.py\", line 439, in converted_call\n",
      "    result = converted_f(*effective_args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/__autograph_generated_filepn_kbeik.py\", line 81, in tf__decode\n",
      "    ag__.for_stmt(ag__.ld(items), None, loop_body_1, get_state_3, set_state_3, (), {'iterate_names': 'item'})\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/autograph/operators/control_flow.py\", line 449, in for_stmt\n",
      "    for_fn(iter_, extra_test, body, get_state, set_state, symbol_names, opts)\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/autograph/operators/control_flow.py\", line 500, in _py_for_stmt\n",
      "    body(target)\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/autograph/operators/control_flow.py\", line 466, in protected_body\n",
      "    original_body(protected_iter)\n",
      "  File \"/tmp/__autograph_generated_filepn_kbeik.py\", line 77, in loop_body_1\n",
      "    ag__.converted_call(ag__.ld(outputs).append, (ag__.converted_call(ag__.ld(handler).tensors_to_item, (ag__.ld(keys_to_tensors),), None, fscope),), None, fscope)\n",
      "                                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/autograph/impl/api.py\", line 441, in converted_call\n",
      "    result = converted_f(*effective_args)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/__autograph_generated_filelfjdorfb.py\", line 39, in tf__tensors_to_item\n",
      "    ag__.if_stmt(ag__.ld(self)._repeated, if_body, else_body, get_state, set_state, ('do_return', 'retval_'), 2)\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/autograph/operators/control_flow.py\", line 1217, in if_stmt\n",
      "    _py_if_stmt(cond, body, orelse)\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/autograph/operators/control_flow.py\", line 1270, in _py_if_stmt\n",
      "    return body() if cond else orelse()\n",
      "                               ^^^^^^^^\n",
      "  File \"/tmp/__autograph_generated_filelfjdorfb.py\", line 35, in else_body\n",
      "    retval_ = ag__.converted_call(ag__.ld(self)._decode, (ag__.ld(image_buffer), ag__.ld(image_format)), None, fscope)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/autograph/impl/api.py\", line 441, in converted_call\n",
      "    result = converted_f(*effective_args)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/__autograph_generated_file7oskc50a.py\", line 80, in tf___decode\n",
      "    image = ag__.converted_call(ag__.ld(control_flow_ops).case, (ag__.ld(pred_fn_pairs),), dict(default=ag__.ld(check_jpeg), exclusive=True), fscope)\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: in user code:\n",
      "\n",
      "    File \"/usr/local/lib/python3.11/dist-packages/object_detection/data_decoders/tf_example_decoder.py\", line 556, in decode  *\n",
      "        tensors = decoder.decode(serialized_example, items=keys)\n",
      "    File \"/usr/local/lib/python3.11/dist-packages/tf_slim/data/tfexample_decoder.py\", line 722, in decode  *\n",
      "        outputs.append(handler.tensors_to_item(keys_to_tensors))\n",
      "    File \"/usr/local/lib/python3.11/dist-packages/tf_slim/data/tfexample_decoder.py\", line 405, in tensors_to_item  *\n",
      "        return self._decode(image_buffer, image_format)\n",
      "    File \"/usr/local/lib/python3.11/dist-packages/tf_slim/data/tfexample_decoder.py\", line 453, in _decode  *\n",
      "        image = control_flow_ops.case(\n",
      "\n",
      "    AttributeError: module 'tensorflow.python.ops.control_flow_ops' has no attribute 'case'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python /tf/tensorflow/models/research/object_detection/model_main_tf2.py \\\n",
    "    --pipeline_config_path={MODEL_FILEPATH} \\\n",
    "    --model_dir ={MODEL_OUTPUT} \\\n",
    "    --alsologtostderr \\\n",
    "    --num_train_steps={NUM_STEPS} \\\n",
    "    --sample_1_of_n_eval_examples=1 \\\n",
    "    --num_eval_steps={NUM_EVAL_STEPS}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
